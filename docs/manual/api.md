# API
ä½¿ç”¨Javascript APIå®ç°è„šæœ¬åŒ–æ“ä½œã€‚

åœ¨è½¯ä»¶çš„å…³äºé¡µé¢ä¸­å¯ä»¥ä¸‹è½½APIæ–‡ä»¶åŒ…ï¼Œè§£å‹ååŒ…å«ç¨‹åºç¤ºä¾‹`main.mjs`å’Œç›¸å…³APIåº“æ–‡ä»¶ã€‚
æ‰€æœ‰æ¥å£å‡åŒ…å«TSç±»å‹å®šä¹‰ï¼Œæ–¹æ³•åå’Œå‚æ•°åå‡æœ‰è¯­ä¹‰åŒ–å‘½åï¼Œæ–¹ä¾¿ä½¿ç”¨ã€‚

::: info
å‰ç«¯é¡µé¢å³ä½¿ç”¨æ­¤APIè¿›è¡Œæ•°æ®äº¤äº’ï¼Œä½ ç”šè‡³å¯ä»¥åŸºäºæ­¤æ¥å£å¼€å‘è‡ªå·±çš„å‰ç«¯é¡µé¢ğŸ˜Š
:::

::: warning
APIæ–‡ä»¶åŒ…ä¸‹è½½è¿‡ç¨‹ä¸­å³åœ¨`main.mjs`ä¸­åŒ…å«äº†ç”¨æˆ·æˆæƒä¿¡æ¯ï¼Œå› æ­¤è¯·å‹¿ç›´æ¥å°†APIæ–‡ä»¶åŒ…åˆ†äº«ç»™ä»–äººã€‚
:::


## ç¤ºä¾‹
æŠ“å–ArXivä¸Šæœ€æ–°50æ¡CVè®ºæ–‡ä¿¡æ¯ï¼Œå¹¶åŠ å…¥åˆ°æ•°æ®åº“ä¸­ã€‚

::: details å‰ç½®ä»£ç 
å®‰è£…ä¾èµ–
```sh
npm install fast-xml-parser
```
å·¥å…·å‡½æ•°
```javascript
import { XMLParser } from 'fast-xml-parser';
export async function fetchArxivFeed(
    maxResults = 10,
    searchQuery = 'cat:cs.AI OR cat:cs.CV',
    sortBy = 'submittedDate',
    sortOrder = 'descending',
  ){
    const query = `search_query=${encodeURIComponent(searchQuery)}&sortBy=${sortBy}&sortOrder=${sortOrder}&max_results=${maxResults}`;
    const apiUrl = `https://export.arxiv.org/api/query?${query}`;
    const response = await fetch(apiUrl, { method: 'GET', });
    const xmlData = await response.text();
    const parser = new XMLParser();
    const parsedData = parser.parse(xmlData);
    let entries = parsedData.feed.entry;
    if (!Array.isArray(entries)) { entries = [entries]; }
    function getAuthors(entry){
      if (Array.isArray(entry.author)) { return entry.author.map((author) => author.name); }
      else if (entry.author) { return [entry.author.name]; }
      else return [];
    }
    if (entries && Array.isArray(entries)) {
      const articles = entries.map((entry) => {
        const id = entry.id.split('/').pop().split('v')[0];
        const link = entry.id;
        const title = entry.title;
        const abstract = entry.summary;
        const authors = getAuthors(entry);
        const updatedTime = entry.updated;
        const publishedTime = entry.published;
        const bibtex = `@article{${id},
        title = {${title}},
        author = {${authors.join(' and ')}},
        journal = {arXiv preprint arXiv:${id}},
        year = {${publishedTime.slice(0, 4)}},
        url = {${link}}
        }`;
        return { id, link, title, abstract, authors, updatedTime, publishedTime, bibtex};
      });
  
      return articles;
    } else { throw new Error('Invalid feed data'); }
}
```
:::

```javascript
// Lires-API v1.7.3 (Accessed: ...)
import { ServerConn } from "./lib/api.js";

const context = {
    endpoint: "https://...",
    key: "..."
}
// lires æœåŠ¡å™¨è¿æ¥å¯¹è±¡
const conn = new ServerConn(()=>context.endpoint, ()=>context.key)

// æŠ“å–æœ€æ–°50æ¡ArXivä¸Šçš„æ–‡ç« 
const articles = await fetchArxivFeed(50, 'cat:cs.CV');

for (const article of articles) {
    try{
        // æ·»åŠ åˆ°æ•°æ®åº“
        await conn.updateDatapoint(null, {
          bibtex: article.bibtex, 
          tags: ['arxiv-collect'], 
          url: article.link
        });
        console.log(`Article "${article.id}" added to the database.`);
    }
    catch(e){
        // å¦‚æœè¿”å›409åˆ™è¯´æ˜å·²å­˜åœ¨
        console.error(`Error adding article "${article.id}" to the database: ${e}`);
    }
}
```